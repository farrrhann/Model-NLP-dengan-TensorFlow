# -*- coding: utf-8 -*-
"""NLP_Farhan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yaoOMEtKm_rylHqsYN87TwfnWB4y7C5b

*   Nama: Farhan
*   Email: farhanarafiq2401@gmail.com
*   Kota: Pontianak

In India, every year lacs of students sit for competitive examinations like JEE Advanced, JEE Mains, NEET, etc. These exams are said to be the gateway to get admission into India's premier Institutes such as IITs, NITs, AIIMS, etc. Keeping in mind that the competition is tough as lacs of students appear for these examinations, there has been an enormous development in Ed Tech Industry in India, fortuning the dreams of lacs of aspirants via providing online as well as offline coaching, mentoring, etc. This particular dataset consists of questions/doubts raised by students preparing for such examinations.

The dataset contains Students-questions.csv file in version 1 as of now.
Inside the CSV file, we have two columns:

eng: The full question or description of the questions
Subject: Which subject does the question belong to. It has 4 classes, Physics, Chemistry, Biology, and Mathematics.
"""

import pandas as pd

df = pd.read_csv('subjects-questions.csv')

df.head

# untuk melihat apakah terdapat missing value
# true berarti ada, false berarti tidak ada
df.isnull().values.any()

# karena data kategori maka dilakukan proses one hot encoding
course = pd.get_dummies(df.Subject)
df_baru = pd.concat([df, course], axis=1)
df_baru = df_baru.drop(columns='Subject')

df_baru.head()

# mengubah nilai nilai dari dataframe ke dalam tipe data numpy array
questions = df_baru['eng'].values
label = df_baru[['Biology', 'Chemistry', 'Maths', 'Physics']].values

from sklearn.model_selection import train_test_split

# membagi data training dan data testing
questions_latih, questions_test, label_latih, label_test = train_test_split(questions, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer

from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(questions_latih) 
tokenizer.fit_on_texts(questions_test)

sekuens_latih = tokenizer.texts_to_sequences(questions_latih)
sekuens_test = tokenizer.texts_to_sequences(questions_test)

padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf

class Callback(tf.keras.callbacks.Callback): 
    def on_epoch_end(self, epoch, logs={}): 
        if(logs.get('accuracy') > 0.90 and logs.get('val_accuracy') > 0.90):
            print("\nReached 90% accuracy") 
            self.model.stop_training = True 
     
callbacks = Callback()

# pemodelan sequential dengan menerapkan embedding dan LSTM
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(4, activation='softmax')
])

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

num_epochs = 30
history = model.fit(padded_latih, label_latih, epochs=num_epochs, 
                        validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

import matplotlib.pyplot as plt

# membuat plot loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# membuat plot akurasi
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()